{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pysegreg run - Time based"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Instructions**\n",
    "\n",
    "For fast processing, you can just change the following variables **before running**:\n",
    "* path/name at **Input file** cell (select the file you want to use)\n",
    "* path/name at **Input and generate Time Matrix** cell (create time matrix from local file)\n",
    "* bandwidth and weigth method at **compute population intensity** cell\n",
    "* file name in the variable **fname** at section **Save results to a local file** (the file you want to save results)\n",
    "\n",
    "*make sure you don't use a name already used or the file will be replaced*\n",
    "\n",
    "With the previous steps in mind, just click on **Cell** menu and select **Run All**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "np.seterr(all='ignore')\n",
    "import pandas as pd\n",
    "from decimal import Decimal\n",
    "import time\n",
    "import csv\n",
    "\n",
    "# Import python script with Pysegreg functions\n",
    "from segregationMetrics import Segreg\n",
    "\n",
    "# Instantiate segreg as cc\n",
    "cc = Segreg()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input file\n",
    "\n",
    "**Attention to the new data structure for input !!!**\n",
    "\n",
    "Change your input file with path/name in the cell below to be processed.\n",
    "\n",
    "**Data Format**  \n",
    "**ID | X | Y | group 1 | group 2 | group n**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[  3.33245530e+05,   7.39477232e+06,   7.70000000e-01, ...,\n",
       "           3.65000000e+00,   1.49000000e+00,   3.45000000e+00],\n",
       "        [  3.33657950e+05,   7.39531053e+06,   5.10000000e-01, ...,\n",
       "           8.41000000e+00,   2.12000000e+00,   1.14000000e+00],\n",
       "        [  3.33381780e+05,   7.39420259e+06,   1.42000000e+00, ...,\n",
       "           2.20800000e+01,   2.88000000e+01,   9.11000000e+00],\n",
       "        ..., \n",
       "        [  3.00003210e+05,   7.39509971e+06,   2.00000000e-01, ...,\n",
       "           7.60000000e-01,   2.49000000e+00,   1.69000000e+00],\n",
       "        [  3.04217510e+05,   7.40542844e+06,   5.00000000e-02, ...,\n",
       "           1.40000000e-01,   6.20000000e-01,   2.20000000e-01],\n",
       "        [  2.97174290e+05,   7.41325052e+06,   0.00000000e+00, ...,\n",
       "           1.00000000e-02,   1.30000000e-01,   7.00000000e-02]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.readAttributesFile('/Users/sandrofsousa/Downloads/valid/Segreg sample.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input and generate Time Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a list with the time files to be processed.\n",
    "path = \"../tempos/p\"  # adjust this path according to data source\n",
    "file_list = []\n",
    "\n",
    "for i in range(1, 20):\n",
    "    file_list.append(path + str(i) +\"_TP.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19.75668250322342 minutes for processing\n"
     ]
    }
   ],
   "source": [
    "# Create the distance matrix reading local files\n",
    "start = time.time()\n",
    "\n",
    "# create an empty matrix to be updated with data\n",
    "matrix = np.empty([18953, 18953])  # this shape may change due to new matrice sizes\n",
    "for file in file_list:\n",
    "    with open(file, \"r\") as data:\n",
    "        parser = csv.reader(data, delimiter=\";\")\n",
    "        next(parser)  # skip header\n",
    "        for line in parser:\n",
    "            origin = int(line[1]) -1\n",
    "            destiny = int(line[2]) -1\n",
    "            travel_time = float(line[3])\n",
    "            matrix[origin, destiny] = travel_time  #update position based on index\n",
    "            \n",
    "print(\"--- %s minutes for processing ---\" % round(time.time() - start/60, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures\n",
    "\n",
    "**Compute Population Intensity based on time**\n",
    "\n",
    "**For non spatial result, please comment the function call at: \"cc.locality= ...\" **\n",
    "\n",
    "* to comment a code use # in the begining of the line\n",
    "\n",
    "The Time matrix is used to compute population intensity at this step. Change the \n",
    "parameters according to your needs. Parameters are:  \n",
    "* **bandwidth** - is set to be 5000m by default, you can change it here  \n",
    "* **weightmethod** - 1 for gaussian, 2 for bi-square and empty for moving window\n",
    "* **matrix** - Time matrix in a simetric shape (variable name computed previously)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 18953 into shape (1,460)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-167748b60dfa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcal_timeMatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbandwidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweightmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"--- %s seconds for processing ---\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/sandrofsousa/workspace/resolution/Pysegreg/segregationMetrics.py\u001b[0m in \u001b[0;36mcal_timeMatrix\u001b[0;34m(self, bandwidth, weightmethod, matrix)\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mindex_sub\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_subgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m                 \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_local\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     85\u001b[0m                 \u001b[0mweight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetWeight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbandwidth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweightmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mlocality_temp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_sub\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_sub\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 18953 into shape (1,460)"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "cc.locality = cc.cal_timeMatrix(bandwidth=10, weightmethod=1, matrix=matrix)\n",
    "\n",
    "print(\"--- %s seconds for processing ---\" % round(time.time() - start_time, 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For validation only  \n",
    "Remove the comment (#) if you want to see the values and validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'To select locality for a specific line (validation), use the index in[x,:]'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.set_printoptions(threshold=np.inf)\n",
    "# print('Location (coordinates from data):\\n', cc.location)\n",
    "# print()\n",
    "# print('Population intensity for all groups:\\n', cc.locality)\n",
    "\n",
    "'''To select locality for a specific line (validation), use the index in[x,:]'''\n",
    "# where x is the number of the desired line\n",
    "\n",
    "# cc.locality[5,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute local Dissimilarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diss_local = cc.cal_localDissimilarity()\n",
    "diss_local = np.asmatrix(diss_local).transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute global Dissimilarity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "diss_global = cc.cal_globalDissimilarity()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Compute local Exposure/Isolation**  \n",
    "expo is a matrix of n_group * n_group therefore, exposure (m,n) = rs[m,n]  \n",
    "the columns are exporsure m1 to n1, to n2... n5, m2 to n1....n5  \n",
    "- m,m = isolation index of group m\n",
    "- m,n = expouse index of group m to n\n",
    "\n",
    "Result of all combinations of local groups expousure/isolation  \n",
    "To select a specific line of m to n, use the index [x]  \n",
    "Each value is a result of the combinations m,n  \n",
    "e.g.: g1xg1, g1xg2, g2,g1, g2xg2 = isolation, expousure, // , isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expo_local = cc.cal_localExposure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Compute global Exposure/Isolation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "expo_global = cc.cal_globalExposure()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute local Entropy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entro_local = cc.cal_localEntropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute global Entropy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "entro_global = cc.cal_globalEntropy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute local Index H**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idxh_local = cc.cal_localIndexH()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute global Index H**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "idxh_global = cc.cal_globalIndexH()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "**Prepare data for saving on a local file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concatenate local values from measures\n",
    "if len(cc.locality) == 0:\n",
    "    results = np.concatenate((expo_local, diss_local, entro_local, idxh_local), axis=1)\n",
    "else:\n",
    "    results = np.concatenate((cc.locality, expo_local, diss_local, entro_local, idxh_local), axis=1)\n",
    "\n",
    "# Concatenate the results with original data\n",
    "output = np.concatenate((cc.tract_id, cc.attributeMatrix, results),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = ['id','x','y']\n",
    "\n",
    "for i in range(cc.n_group):\n",
    "    names.append('group_'+str(i))\n",
    "\n",
    "if len(cc.locality) == 0:    \n",
    "    for i in range(cc.n_group):\n",
    "        for j in range(cc.n_group):\n",
    "            if i == j:\n",
    "                names.append('iso_' + str(i) + str(j))\n",
    "            else:\n",
    "                names.append('exp_' + str(i) + str(j))\n",
    "            \n",
    "    names.append('dissimil')\n",
    "    names.append('entropy')\n",
    "    names.append('indexh')\n",
    "    \n",
    "else:\n",
    "    for i in range(cc.n_group):\n",
    "        names.append('intens_'+str(i))\n",
    "        \n",
    "    for i in range(cc.n_group):\n",
    "        for j in range(cc.n_group):\n",
    "            if i == j:\n",
    "                names.append('iso_' + str(i) + str(j))\n",
    "            else:\n",
    "                names.append('exp_' + str(i) + str(j))\n",
    "            \n",
    "    names.append('dissimil')\n",
    "    names.append('entropy')\n",
    "    names.append('indexh')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Save Local and global results to a file**\n",
    "\n",
    "The paramenter **fname** corresponds to the folder/filename, change it as you want.  \n",
    "To save on a diferent folder, use the \"/\" to pass the directory.  \n",
    "The local results will be saved using the name defined and adding the **\"_local\"** postfix to file's name.  \n",
    "The global results are automatically saved using the same name with the addiction of the postfix **\"_globals\".**  \n",
    "\n",
    "It's recommended to save on a different folder from the code, e.g.: a folder named result.\n",
    "\n",
    "**The fname value should be changed for any new executions or the local file will be overwrited!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fname = \"/Users/sandrofsousa/Downloads/valid/result\"\n",
    "\n",
    "output = pd.DataFrame(output, columns=names)\n",
    "output.to_csv(\"%s_local.csv\" % fname, sep=\",\", index=False)\n",
    "with open(\"%s_global.txt\" % fname, \"w\") as f:\n",
    "    f.write('Global dissimilarity: ' + str(diss_global))\n",
    "    f.write('\\nGlobal entropy: ' + str(entro_global))\n",
    "    f.write('\\nGlobal Index H: ' + str(idxh_global))\n",
    "    f.write('\\nGlobal isolation/exposure: \\n')\n",
    "    f.write(str(expo_global))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
